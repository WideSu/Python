#goal:
#In this project, we use unsupervised learning models to cluster unlabeled documents into different groups, visualize the results and identify their latent topics/structures.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#basic operation:
##load data:
import numpy as np
import pandas as pd
df = pd.read_csv('data.tsv',sep='\t',header=0,error_bad_lines=Fales) #tsv is tab seperated file (csv is comma seperated file); header=0 means the head is row[0]; error_bad_lines=Fales means automatically deal with possible error.
df.head()

##missing value:
df.info()
df.isnull().sum()
df.dropna(subset=['review_body'],inplace=True) #review_body column is the column that we care about
df.isnull().sum()

##use first 1000 data as training data:
data = df.loc[:1000,'review_body'].tolist() #tolist() transfer matrix to list
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#tokenizing and stemming:
##tokenizing means split sentence into multiple single words
##the key is to find the stop word. for example, xx's this 's indicates the end of word.
import nltk
stopwords = nltk.corpus.stopwords.words('english') #put normal words into stopwords list
stopwords.append("'s")
stopwords.append("'m")
stopwords.append("n't")
stopwords.append("br")

##stemming means put words into the original form. for example, 'learn', 'learns', 'learning' acutually stand for same word 'learn'
##combine tokenizing and stemming:
from nltk.stem.snowball import SnowballStemmer
import re
stemmer = SnowballStemmer('english')

--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#TF-IDF:
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#K-means clustering:
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Latent Dirichlet Allocation:
--------------------------------------------------------------------------------------------------------------------------------------------------------------------

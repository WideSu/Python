#goal:
#In this project, we use unsupervised learning models to cluster unlabeled documents into different groups, visualize the results and identify their latent topics/structures.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#basic operation:
##load data:
import numpy as np
import pandas as pd
df = pd.read_csv('data.tsv',sep='\t',header=0,error_bad_lines=Fales) #tsv is tab seperated file (csv is comma seperated file); header=0 means the head is row[0]; error_bad_lines=Fales means automatically deal with possible error.
df.head()
  ->marketplace	customer_id	review_id	product_id	product_parent	product_title	                                      product_category	star_rating	helpful_votes	total_votes	vine	verified_purchase	review_headline	                            review_body	                                        review_date
  0	US	3653882	        R3O9SGZBVQBV76	B00FALQ1ZC	937001370	Invicta Women's 15150 "Angel" 18k Yellow Gold ...	  Watches	          5	          0	          0	N	    Y	                Five Stars	                            Absolutely love this watch! Get compliments al...	  2015-08-31
  1	US	14661224	RKH8BNC3L5DLF	B00D3RGO20	484010722	Kenneth Cole New York Women's KC4944 Automatic...	  Watches	          5	          0	          0	N	    Y	                I love thiswatch it keeps time wonderfully  I love this watch it keeps time wonderfully.	  2015-08-31
  2	US	27324930	R2HLE8WKZSU3NL	B00DKYC7TK	361166390	Ritche 22mm Black Stainless Steel Bracelet Wat...	  Watches	          2	          1	          1	N	    Y	                Two Stars	                            Scratches	                                          2015-08-31
  3	US	7211452	        R31U3UH5AZ42LL	B000EQS1JW	958035625	Citizen Men's BM8180-03E Eco-Drive Stainless S...	  Watches	          5	          0	          0	N	    Y	                Five Stars	                            It works well on me. However, I found cheaper ...	  2015-08-31
  4	US	12733322	R2SV659OUJ945Y	B00A6GFD7S	765328221	Orient ER27009B Men's Symphony Automatic Stain...	  Watches	          4	          0	          0	N	    Y	                Beautiful face, but cheap sounding link     Beautiful watch face. The band looks nice all...	  2015-08-31


##missing value:
df.isnull().sum()
  ->marketplace            0
    customer_id            0
    review_id              0
    product_id             0
    product_parent         0
    product_title          2
    product_category       0
    star_rating            0
    helpful_votes          0
    total_votes            0
    vine                   0
    verified_purchase      0
    review_headline        7
    review_body          148
    review_date            4
    dtype: int64
df.dropna(subset=['review_body'],inplace=True) #review_body column is the column that we care about
df.isnull().sum()
  ->marketplace          0
    customer_id          0
    review_id            0
    product_id           0
    product_parent       0
    product_title        2
    product_category     0
    star_rating          0
    helpful_votes        0
    total_votes          0
    vine                 0
    verified_purchase    0
    review_headline      7
    review_body          0
    review_date          4
    dtype: int64

##use first 1000 data as training data:
data = df.loc[:1000,'review_body'].tolist() #tolist() transfer matrix to list
print(data[0])
  ->Absolutely love this watch! Get compliments almost every time I wear it. Dainty.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#tokenizing and stemming:
##tokenizing means split sentence into multiple single words
##the key is to find the stop word. for example, xx's this 's indicates the end of word.
import nltk
stopwords = nltk.corpus.stopwords.words('english') #put normal words into stopwords list
stopwords.append("'s")
stopwords.append("'m")
stopwords.append("n't")
stopwords.append("br")

##stemming means put words into the original form. for example, 'learn', 'learns', 'learning' acutually stand for same word 'learn'
##combine tokenizing and stemming:
from nltk.stem.snowball import SnowballStemmer
import re
stemmer = SnowballStemmer('english')
###define function:
def tokenization_and_stemming(text):
  tokens = []
  for word in nltk.word_tokenzize(text): #exclude stopwords and tokenize the document, generate a list of string
    if word.lower() not in stopwords:
      tokens.append(word.lower())
  filtered_tokens = []
  for token in tokens:
    if re.search('[a-zA-Z]',token): #re.search will filter token that does not have letters
      filtered_tokens.append(token)
  stems = [stemmer.stem(t) for t in filtered_tokens]
  return stems

##example:
tokenization_and_stemming(data[0])
  ->['absolut','love','watch','get','compliment','almost','everi','time','wear','dainti']
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#TF-IDF:
##TF: Term Frequency (wordA in document/total word in document)
##IDF: Inverse Document Frequency (log(total number of documents in corpus)/(number of document where wordA appears + 1))
##use TfidfVectorizer to create tf-idf matrix
tfidf_model = TfidfVectorizer(max_df=0.99,max_features=1000,min_df=0.01,stop_words='english',use_idf=True,tokenizer=tokenization_and_stemming,ngram_range=(1,1))
tfidf_matrix = tfidf_model.fit_transform(data)

##check the parameter 
tfidf_model.get_params()
  ->{'analyzer': 'word',
     'binary': False,
    'decode_error': 'strict',
    'dtype': numpy.float64,
    'encoding': 'utf-8',
    'input': 'content',
    'lowercase': True,
    'max_df': 0.99,
    'max_features': 1000,
    'min_df': 0.01,
    'ngram_range': (1, 1),
    'norm': 'l2',
    'preprocessor': None,
    'smooth_idf': True,
    'stop_words': 'english',
    'strip_accents': None,
    'sublinear_tf': False,
    'token_pattern': '(?u)\\b\\w\\w+\\b',
    'tokenizer': <function __main__.tokenization_and_stemming>,
    'use_idf': True,
    'vocabulary': None}

##get the words
tf_selected_words = tfidf_model.get_feature_names()
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#K-means clustering:
from sklearn.cluster import KMeans
num_clusters = 5
km = KMeans(n_clusters=num_clusters)
km.fit(tfidf_matrix)
clusters = km.labels_.tolist() #km.labels_ shows which cluster the text belongs to

##create DataFrame films from all of the input files:
product = { 'review': df[:1000].review_body, 'cluster': clusters}
frame = pd.DataFrame(product, columns = ['review', 'cluster'])
frame.head(10)
  ->review	                                                cluster
  0	Absolutely love this watch! Get compliments al...	      4
  1	I love this watch it keeps time wonderfully.	          4
  2	Scratches	                                              2
  3	It works well on me. However, I found cheaper ...	      2
  4	Beautiful watch face. The band looks nice all...	      2
  5	i love this watch for my purpose, about the pe...	      4
  6	for my wife and she loved it, looks great and ...	      1
  7	I was about to buy this thinking it was a Swis...	      2
  8	Watch is perfect. Rugged with the metal &#34;B...	      1
  9	Great quality and build.<br />The motors are r...	      1

##number of reviews included in each cluster:
frame['cluster'].value_counts().to_frame() #transfer to dataframe form
  ->	cluster
      2	645
      4	110
      1	104
      0	71
      3	70

##representative words for each cluster:
###we use the top largest number's corresponding word to represent cluster
km.cluster_centers_
  ->array([[0.        , 0.        , 0.        , ..., 0.        , 0.00918964,
            0.        ],
          [0.00308358, 0.        , 0.        , ..., 0.002035  , 0.00357641,
            0.02169867],
          [0.00570286, 0.00446498, 0.00386628, ..., 0.00658131, 0.01765463,
            0.01332411],
          [0.        , 0.        , 0.        , ..., 0.        , 0.00679943,
            0.        ],
          [0.        , 0.04099742, 0.        , ..., 0.01228176, 0.01715362,
            0.00397447]])
km.cluster_centers_.shape
  ->(5, 241) #5 clusters,each contains 241 words' tiidf

##
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Latent Dirichlet Allocation:
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
